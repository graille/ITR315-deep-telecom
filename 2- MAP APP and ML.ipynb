{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTIDpPQVZqqH"
   },
   "source": [
    "# 2. Channel coding and detection: MAP and ML  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEdNQ2HAZqqK"
   },
   "source": [
    "## Detection basics\n",
    "\n",
    "Let $u^k$ be a binary sequence which is to be transmitted through $n$ channel accesses to a memoryless noisy channel defined by a probability density $P_{Y|X}$, i.e. the channel takes as input the sequence $x^n$ and outputs a sequence $y^n$ with probability\n",
    "\n",
    "$$ P(y^n|x^n) = \\prod_{i=1}^n P_{Y|X} (y_i |x_i). $$ \n",
    "\n",
    "The sequence $u^k$ is mapped to the sequence $x^n$ through a mapping which could be an error correction code $f_e(\\cdot)$ concatenated with a constellation mapping. \n",
    "\n",
    "<img src=\"figs/ShannonPointToPoint.png\" width=\"600\">\n",
    "\n",
    "Our purpose is to detect from the received sequence $y^n$, an estimate $\\hat{u}^k$ of the initially transmitted sequence $u^k$. To this end, the receiver consists in a detection rule $f_d(\\cdot)$ which assigns to each sequence $y^n$ an estimate $\\hat{u}^k = f_d(y^n)$. \n",
    "\n",
    "N.B: In this course, we will focus only on deterministic detection rules. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UkXrO3yYZqqN"
   },
   "source": [
    "## Probability of error: misdetection \n",
    "\n",
    "To evaluate the performance of any detection rule $f_d(\\cdot)$, one needs to evaluate the average probability of error. We can define two types of error probabilities: the sequence (block) error probability and the bit error probability: \n",
    "\n",
    "- The sequence error probability is defined as \n",
    "$$ P_s(f_d) = \\mathbb{P} \\left(\\hat{U}^k \\neq U^k \\right).$$\n",
    "\n",
    "- The bit error probability is defined as \n",
    "$$ P_b(f_d) = \\dfrac{1}{k} \\sum_{i=1} \\mathbb{P} \\left(\\hat{U}_i \\neq U_i\\right).$$\n",
    "    \n",
    "Question: What is random in the computation of the error probabilities ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "faLTStB-ZqqP"
   },
   "source": [
    "**Answer:** The noisy channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uurp6zuzZqqV"
   },
   "source": [
    "In practice, the sequence error probability is approximated through Monte Carlo simulations with the Frame Error Rate (FER), or Packet Error Rate (PER), whilst the bit error probability is approximated with the Bit Error Rate (BER). \n",
    "\n",
    "In the following, we characterize the optimal detectors from both the bit and sequence error probabilities perspectives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1O1ccaQEZqqX"
   },
   "source": [
    "##  Sequence detection: MAP, APP and ML \n",
    "\n",
    "The optimal detection rule $f_d(\\cdot)$ which minimizes the sequence probability of error is known as the Maximum A Posteriori (MAP) detector. This detector writes as\n",
    "\n",
    "$$\\hat{u}^k = f_{APP}(y^n) = \\underset{u^k}{argmax} \\  P\\left(u^k| y^n \\right)$$\n",
    "\n",
    "where the probability $P(u^k| y^n)$ is called the A Posterior Probability (APP). \n",
    "\n",
    "Question: Express the A Posterior probability $P\\left(u^k| y^n \\right)$ as a function of the channel probability $P_{Y|X}$, the prior distribution $P\\left(u^k \\right)$, and the mapping $f_e(\\cdot)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "3rnl2CBCZqqb"
   },
   "source": [
    "**Answer:** \n",
    "\n",
    "The FEC encoder is a deterministic and bijective (so injective) function. So, we have the following relation:\n",
    "\n",
    "$$P\\left(y^n| u^k \\right) = P\\left(y^n| f_e(u^k) \\right) = P\\left(y^n| x^k \\right)$$\n",
    "\n",
    "Using the Bayes formula :\n",
    "\n",
    "$$P\\left(u^k| y^n \\right) = \\frac{P\\left(y^n| u^k \\right)P(u^k)}{P\\left(y^n\\right)} = \\frac{P\\left(y^n| x^k \\right)P(u^k)}{P\\left(y^n\\right)} = \\frac{P(u^k)\\prod_{i=1}^n P_{Y|X} (y_i |x_i)}{P\\left(y^n\\right)} = \\frac{P(u^k)\\prod_{i=1}^n P_{Y|X} (y_i |f_{e_i}(u_i))}{P\\left(y^n\\right)}$$\n",
    "\n",
    "Using the total probability formula :\n",
    "\n",
    "$$P\\left(y^n\\right) = \\sum_{i=0}^n P(u^i)P(y^n|u^i) = \\sum_{i=0}^n P(u^i)P(y^n|x^i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_sSI2pcZqqe"
   },
   "source": [
    "In detection theory, we can as well define the so called ML detector given by \n",
    "\n",
    "$$\\hat{u}^k = f_{ML} (y^n) = \\underset{u^k}{argmax} \\  P\\left(y^n| u^k \\right) . $$ \n",
    "\n",
    "Question: Under which condition on the prior distribution $P\\left(u^k \\right) $ are the ML and MAP detectors equivalent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "lY7kOqhfZqqf"
   },
   "source": [
    "**Answer**: According to previous questions\n",
    "\n",
    "$$f_{APP}(y^n) = \\underset{u^k}{argmax} \\  P\\left(u^k| y^n \\right) = \\underset{u^k}{argmax} \\ \\frac{P(u^k)\\prod_{i=1}^n P_{Y|X} (y_i |f_{e_i}(u_i))}{P\\left(y^n\\right)}$$\n",
    "\n",
    "$$f_{ML} (y^n) = \\underset{u^k}{argmax} \\  P\\left(y^n| u^k \\right) = \\underset{u^k}{argmax} \\ \\prod_{i=1}^n P_{Y|X} (y_i |f_{e_i}(u_i))$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4y6i3FKMZqqj"
   },
   "source": [
    "Question: Do you know of an algorithm which implements the sequence MAP detector? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "rTjNjj2KZqqk"
   },
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXDUmDMWZqqm"
   },
   "source": [
    "Question: Consider a Gaussian channel with variance $\\sigma^2$, i.e.,\n",
    "\n",
    "  $$ P(y|x) = \\dfrac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left( \\dfrac{-(y-x)^2}{2 \\sigma^2} \\right) , $$\n",
    "\n",
    "over which we wish to communicate a binary sequence of length $k$.\\\\\n",
    "\n",
    "Question: Write the sequence MAP criterion for a mapping $f_e(\\cdot)$ under the assumption of a uniform prior distribution $P(u^k) = 2^{-k} $. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "oONQ-d5nZqqo"
   },
   "source": [
    "**Answer**:  \n",
    "\n",
    "$$f_{APP}(y^n) = \\underset{u^k}{argmax} \\prod_{i=1}^n P_{Y|X} (y_i^n |f_{e_i}(u^k_i))=\\underset{u^k}{argmax}\\prod_{i=1}^n \\dfrac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left( \\dfrac{-(y_i^n-f_{e_i}(u^k_i))^2}{2 \\sigma^2} \\right)=\\underset{u^k}{argmax} \\sum_{i=1}^n-(y_i^n-f_{e_i}(u^k_i))^2=\\underset{u^k}{argmin}\\sum_{i=1}^n d(y_i^n,x_i^k)^2=\\underset{u^k}{argmin}~d(y^n,x^k)^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUwmxc2dZqqp"
   },
   "source": [
    "Question: Consider a Binary Symmetric Channel with crossover probability $p$, i.e., \n",
    "\n",
    "  $$ P(y|x) =  p^{x \\oplus y} (1-p)^{1 - x \\oplus y}  , $$\n",
    "  \n",
    "over which we wish to communicate a binary sequence of length $k$. Write the sequence MAP criterion for a mapping $f_e(\\cdot)$ under the assumption of a uniform prior distribution $P(u^k) = 2^{-k} $. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "3zqo5fVdZqqq"
   },
   "source": [
    "**Answer**: $$ \\underset{u^k}{argmax} P(y^n|x^k) =  p^{x^k \\oplus y^n} (1-p)^{1 - x^k \\oplus y^n} = \\underset{u^k}{argmax}\\left( \\dfrac{p}{1-p}\\right)^{x^k \\oplus y^n}, $$\n",
    "Since $p\\leq \\dfrac{1}{2}$ generally then $\\dfrac{p}{1-p}  \\in [0;1]$ we have : \n",
    "$$\\underset{u^k}{argmax}~P(y^n|x^k) = \\underset{u^k}{argmin}~{x^k \\oplus y^n}=\\underset{u^k}{argmin}~d_{Hamming}(y^n,x^k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xf4Ab9orZqqs"
   },
   "source": [
    "Question: In the case of uncoded BPSK communication over an AWGN channel, prove that the MAP criterion amounts to a threshold detector and give the value of the threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "7teLh06EZqqt"
   },
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GS0e578jZqqu"
   },
   "source": [
    "##  Bit detection:  MAP and APP  \n",
    "\n",
    "The optimal detection rule from a bit error probability is called the bit-MAP detector. This detector writes as: \n",
    "\n",
    "$$\\hat{u}_i = f_{APP}(y^n) = \\underset{u_i}{argmax} \\  P(u_i| y^n) . $$\n",
    "\n",
    "Question: Express the A Posterior probability $P(u_i| y^n)$ as a function of the channel probability $P_{Y|X}$ and the prior distribution $P(u^k)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "rAb68321Zqqv"
   },
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a4gyQJGLZqqv"
   },
   "source": [
    "Question: Do you know of an algorithm to implement the bit-MAP detector? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "lKi-DeP3Zqq6"
   },
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-1GRY4yZqq7"
   },
   "source": [
    "## Detection over classical channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJYkM_omZqq7"
   },
   "source": [
    "###  1. Uncoded transmissions: AWGN and BSC channels\n",
    "\n",
    "Based on the communication chain you implemented previously, simulate and compute the BER of the MAP sequence decoder for uncoded communication over an AWGN channel. Compare its performance with the theoretic curve of BER as a function of $E_b/N_0$. Comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b2vaSM5iZqq8"
   },
   "outputs": [],
   "source": [
    "# Type your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gcsg5CDQZqrA"
   },
   "source": [
    "###  2. Coded transmission: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_Y6IT1hZqrB"
   },
   "source": [
    "Based on the communication chain you implemented previously, simulate and compute the BER of the MAP sequence decoder for communication over an AWGN channel with a given linear block error correction code ( choose among Hamming, Polar, LDPC, ...). This will be the reference for further work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1581411275010,
     "user": {
      "displayName": "Thibault Piana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBBEkRBFiuL8UuI8IqCO-yLr4I915lnrATVAqmiRQ=s64",
      "userId": "06996799130223842064"
     },
     "user_tz": -60
    },
    "id": "0ulbuaKlZqrB",
    "outputId": "741c7c81-be3c-4ff0-ee9a-d3e8df0bbdfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([1, 2, 4])\n",
    "\n",
    "print(np.sum(a == b))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2- MAP APP and ML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
